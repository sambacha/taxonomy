{
  "title": "Rationality is Self-Defeating in Permissionless Systems",
  "description": "How to deploy your Next.js apps on Vercel.",
  "date": "2023-01-02T00:00:00.000Z",
  "published": true,
  "image": "/images/blog/que-eth.png",
  "authors": [
    "Bryan Ford"
  ],
  "body": {
    "raw": "\n<Callout>\n> Many blockchain and cryptocurrency fans seem to prefer building and analyzing\n> decentralized systems in a rational or “greedy behavior” failure model, rather\n> than a Byzantine or “arbitrary behavior” failure model. Many of the same\n> blockchain and cryptocurrency fans also like open, permissionless systems like\n> Bitcoin and Ethereum, which anyone can join and participate in using weak\n> identities such as anonymous cryptography key pairs.\n> _by [Bryan Ford](https://bford.info/) and\n> [Rainer Böhme](https://informationsecurity.uibk.ac.at/people/rainer-boehme/) —\n> [PDF preprint](https://arxiv.org/pdf/1910.08820.pdf) version available_\n</Callout>\n\n\n\nMany blockchain and cryptocurrency fans seem to prefer building and analyzing\ndecentralized systems in a rational or “greedy behavior” failure model, rather\nthan a Byzantine or “arbitrary behavior” failure model. Many of the same\nblockchain and cryptocurrency fans also like open, permissionless systems like\nBitcoin and Ethereum, which anyone can join and participate in using weak\nidentities such as anonymous cryptography key pairs.\n\nWhat most of these heavily-overlapping sets of fans do not seem to realize,\nhowever, is that rationality assumptions are self-defeating in open\npermissionless systems with weak identities. A fairly simple metacircular\nargument – a kind of\n“[Gödel's incompleteness theorem](https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems)\nfor rationality” – shows that for any system _S_ that makes _any_ behavioral\nassumption, including but not limited to a rationality assumption, a rational\nattacker both exists and _has an incentive_ to defeat that behavioral\nassumption, thereby violating that assumption and exhibiting Byzantine behavior\nfrom the perspective of the system.\n\nAs a quick summary of the argument we will expand below, suppose a\npermissionless system like Bitcoin is secure against rational attacks, but has\nsome weakness against irrational Byzantine attacks in which the attacker would\nlose money. Because the system is open, permissionless, and exists within a\nlarger ecosystem, a rational attacker can find ways to “bet against” Bitcoin's\nsecurity in _other_ financially-connected systems (e.g., Ethereum), making a\nprofit _outside of_ Bitcoin on this attack against Bitcoin. An attack that\nappears irrational in the context of Bitcoin may be perfectly rational in the\ncontext of the larger ecosystem.\n\nFor this reason, an open permissionless system designed to be secure only\nagainst rational adversaries is actually just _insecure_, unless it remains\nsecure even when the “rational” participants become fully Byzantine. Given this,\none might as well have designed the permissionless system in a Byzantine model\nin the first place. The rationality assumption offers no actual benefit, but\nmerely can make an insecure system appear secure under flawed analysis.\n\nThis blog post is based partly on ideas in\n[Rainer Böhme's talk](https://web.archive.org/web/20191124192837/https://bdlt.school/files/slides/talk-rainer-b%C3%B6hme-a-primer-on-economics-for-cryptocurrencies.pdf)\nat the recent\n[BDLT Summer School in Vienna](https://web.archive.org/web/20210416231544/https://bdlt.school/).\nWhile formalizing the argument would require some effort, we thought it would be\nworth at least sketching the argument intuitively for the public record.\n\n## Threat Modeling: Honest, Byzantine, and Rational Participants\n\nIn designing or analyzing the security of any decentralized system, we must\ndefine the system's _threat model_, and in particular our assumptions about the\nbehaviors of the participants in the system. An _honest_, _correct_, or\n_altruistic_ participant is one that we assume to follow the system's protocol\nrules as specified, hence representing a “well-behaved” participant exhibiting\nno adversarial behavior.\n\nA _Byzantine_ participant, named after the\n[Byzantine Generals Problem](http://theory.stanford.edu/~trevisan/cs174/byzantine.pdf),\nis one we make _no_ assumptions about. A Byzantine participant can behave in\n_arbitrary_ fashion, without restriction, and hence by definition represents the\nstrongest possible adversary.\n\nWe would like to build systems that could withstand _all_ participants being\nByzantine, but this appears fundamentally impossible. We therefore in practice\nhave to make threshold security assumptions, such as that over two-thirds of the\nparticipants in classic Byzantine consensus protocols are honest, or that the\nparticipants controlling over half the hashpower in Bitcoin are well-behaved.\n\nEven with threshold assumptions, however, building systems that resist Byzantine\nbehavior is extremely difficult, and the resulting systems are often much more\ncomplex and inefficient than systems tolerating weaker adversaries. We may\ntherefore be tempted to improve a design's simplicity or efficiency by making\nstronger assumptions about the behavior of adversarial participants, effectively\nweakening the assumed adversary.\n\n![Types of adversaries](https://bford.info/2019/09/23/rational/adversaries.svg)\n\nOne such popular assumption, especially in economic circles, is _rationality_.\nIn essence, we assume that rational participants may deviate from the rules in\narbitrary ways but _only when doing so is in their economic self-interest_,\nimproving their expected rewards – usually but not always financial – in\ncomparison with following the rules honestly.\n\nBy assuming that adversarial participants are rational rather than Byzantine, we\nneed not secure the system against _all_ possible participant behaviors, such as\nagainst participants who pay money with no reward merely to sow chaos and\ndestruction. Instead, we merely need to prove that the system is _incentive\ncompatible_, for example by showing that its rules represent a Nash equilibrium,\nin which deviations from the equilibrium will not give participants a greater\nfinancial reward.\n\nBesides simplicity and efficiency, another appeal of rationality assumptions is\nthe promise of _strengthening_ the system's security by lowering the threshold\nof participants we assume to be fully honest. To circumvent the classical\nByzantine consensus requirement that fewer than one third of participants may be\nfaulty, for example, we might hope to tolerate closer to 50%, or even 100%, of\nparticipants being “adversarial” if we assume they are rational and not\nByzantine. Work on\n[the BAR model (Byzantine-Altruistic-Rational)](http://www.cs.utexas.edu/~lorenzo/papers/sosp05.pdf)\nand\n[_(k,t)_\\-robustness](http://www.cs.utexas.edu/~lorenzo/papers/Abraham11Distributed.pdf)\nexemplifies this goal, which sometimes appears achievable in closed systems with\nstrong identities. But a direct implication of our metacircular argument is that\nan _open_ system cannot generally be secure if all participants are either\nByzantine or rational.\n\n## Assumptions Underlying the Argument\n\nThe metacircular argument makes three main assumptions.\n\nFirst, the system _S_ under consideration is open and permissionless, allowing\nanyone to join and participate in the system using only weak, anonymous\nidentities such as bare cryptographic key pairs. Identities in _S_ need not even\nbe costless provided their price is modest: the argument still works even if _S_\nimposes membership fees or requires new wallet keys to be “mined”, for example.\nProof-of-Work cryptocurrencies such as Bitcoin and Ethereum, Proof-of-Stake\nsystems such as Algorand and Ouroboros, and most other permissionless systems\nseem to satisfy this openness property. Because participation is open to anyone\nglobally and can be anonymous, we cannot reasonably expect police or governments\nto protect _S_ from attack: even if they wanted to and considered it their job,\nthey would not be able to find or discipline a smart rational attacker who might\nbe attacking from anywhere around the globe, especially from a country with weak\ninternational agreements and extradition rules. Thus, _S_ must “stand on its\nown”, by successfully either withstanding or disincentivizing attacks coming\nfrom anywhere. (And it will turn out that merely disincentivizing such attacks\nis impossible.)\n\nSecond, the system _S_ does not control a majority of total economic power or\nvalue in the world: i.e., it is not totally economically dominant from a global\nperspective. Instead, there may be (and probably are) actors outside of _S_ who,\nif rationally incentivized to do so, can at least temporarily muster an amount\nof economic power outside of _S_ comparable to or greater than the economic\nvalue within or controlled by _S_. In other words, we assume that _S_ is not the\n“biggest fish in the ocean.” Given that there can be at most one globally\ndominant economic system at a time, it seems neither useful nor advisable to\ndesign systems that are secure only when they are the biggest fish in the ocean,\nbecause almost always they are not.\n\nThird, the system _S_ actually _leverages_ in some fashion the behavioral\nassumption(s) it makes on participants, such as a rationality assumption. That\nis, we assume there exist one or more (arbitrary) behavioral strategies that _S_\nassumes some participants _will not_ follow, such as economically-losing\nbehaviors in the case of rationality. Further, we assume there exists such an\nassumption-violating strategy that will cause _S_ to malfunction or otherwise\ndeviate observably from its correct operation. In fact, we need not assume that\nthis deviant behavior will _always_ succeed in breaking _S_, but only that it\nwill non-negligibly _raise the probability_ of _S_ failing. If this were not the\ncase, and _S_ in fact operates correctly, securely, and indistinguishably from\nits ideal even if participants do violate their behavioral assumptions, then _S_\nis actually Byzantine secure after all. In that case, _S_ is not actually\nbenefiting from its assumptions about participant behavior, which are redundant\nand thus may be simply discarded.\n\n## The Metacircular Argument: Rational Attacks on Rationality\n\nSuppose permissionless system _S_ is launched, and operates smoothly for some\ntime, with all participants conforming to _S_'s assumptions about them. Because\n_S_ is permissionless (assumption 1) and exists in a larger open world\n(assumption 2), new rational participants may arrive at any time, attracted by\n_S_'s success and presumably growing economic value provided there is an\nopportunity to profit from doing so.\n\nConsider a particular newly-arriving participant _P_. _P_ could of course play\nby the rules _S_ assumes of _P_, in which case the greatest immediate economic\nbenefit _P_ could derive from participating in _S_ is some fraction of the total\neconomic value currently embodied in _S_ (e.g., its market cap). For most\nrealistic permissionless systems embodying strong founders' or early-adopters'\nrewards, if _P_ is not one of the original founders of _S_ but arrives\nsubstantially after launch, then _P_'s near-term payoff prospectives from\njoining _S_ is likely bounded to a fairly _small_ fraction of _S_'s total value.\nBut what if there were another strategy _P_ could take, for perfectly _rational_\nand economically-motivated reasons, by which _P_ could in relatively short order\nacquire a _large_ fraction of _S_'s total value?\n\n![Open world with S and S'](https://bford.info/2019/09/23/rational/open-world.svg)\n\nBecause _S_ is permissionless and operating in a larger open world, _P_ is not\nconfined to operating exclusively within the boundaries of _S_. _P_ can also\nmake use of facilities external to _S_. By assumption 2, _P_ may in particular\nhave access to, or be able to borrow temporarily, financial resources comparable\nto or larger than the total value of _S_.\n\nSuppose the facilities external to _S_ include another Ethereum-like\ncryptocurrency _S'_, which includes a smart contract facility with which\ndecentralized exchanges, futures markets, and the like may be implemented. (This\nis not really a separate assumption because even if _S'_ did not already exist,\n_P_ could create and launch it, given sufficient economic resources under\nassumption 2.) Further, suppose that someone (perhaps _P_) has created on\nexternal system _S'_ a decentralized exchange, futures market, or any other\nmechanism by which tokens representing shares of the value of _S_ may be traded\nor speculated upon in the context of _S'_: e.g., a series of tradeable Ethereum\ntokens pegged to _S_'s cryptocurrency or stake units.\n\nNow suppose participant _P_ finds some behavioral strategy that system _S_\ndepends on participants _not_ exhibiting, and that will observably break _S_ –\nor even that just _might_ break _S_ with significant non-negligible probability.\nAssumption 3 above guarantees the existence of such a behavioral strategy,\nunless _S_'s rationality assumptions were in fact redundant and worthless. _P_\nmust merely be clever enough to find and implement such a strategy. It is\npossible this strategy might first require _P_ to pretend to be one or more\nwell-behaved participants of _S_ for a while, to build up the necessary\nreputation or otherwise get correctly positioned in _S_'s state space; a bit of\npatience and persistence on _P_'s part will satisfy this requirement. _P_ may\nalso have to “buy into” _S_ enough to surmount any entry costs or stake\nthresholds _S_ might impose; the external funds _P_ can invoke or borrow by\nassumption 2 can satisfy this requirement, and are bounded by the total value of\n_S_. In general, _S_'s openness by assumption 1 and the existence of a\ncorrectness-violating strategy by assumption 3 ensures that there exists some\ncourse of action and supply of external resources by which _P_ can position\nitself to violate _S_'s behavioral assumption.\n\nIn addition to infiltrating and positioning itself within _S_, _P_ also invokes\nor borrows enough external funds and uses them to short-sell (bet against)\nshares of _S_'s value massively in the context of the external system _S'_,\nwhich (unlike _S_) _P_ trusts will remain operational and hold its value\nindependently of _S_. Provided _P_ reaches this short-selling position gradually\nand carefully enough to avoid revealing its strategy early, the funds _P_ must\ninvoke or borrow for this purpose must be bounded by some fraction of the total\neconomic value of _S_. And provided there are at least some participants and/or\nobservers of _S_ who believe that _S_ is secure and will remain operating\ncorrectly, and are willing to bet to that effect on _S'_, _P_ will eventually be\nable to build its short position.\n\nFinally, once _P_ is positioned correctly within both _S_ and _S'_, _P_ then\nlaunches its assumption-violating behavior in _S_ that will observably cause _S_\nto fail as per assumption 2. This might manifest as a denial-of-service attack,\na correctness attack, or in any other fashion. The only requirement is that\n_P_'s behavior creates an _observable_ failure, which a nontrivial number of the\nexisting participants in _S_ believed would not happen because they believed in\n_S_ and its threat model. The fact that _S_ is now observed to be broken, and\nits basic design assumptions manifestly violated, causes the shares of _S_'s\nvalue to drop precipitously on external market _S'_, on which _P_ takes a\nhandsome profit. Perhaps _S_ recovers and continues, or perhaps it fails\nentirely – but either way, _P_ has essentially transferred a significant\nfraction of system _S_'s economic value from system _S_ itself to _P_'s own\nshort-sold position on external market _S'_. And to do so, _P_ needed only to\nfind a way – any way – to _surprise_ all those who believed _S_ was secure and\nthat its threat model accurately modeled _S_'s real-world participants.\n\nEven if _P_'s assumption-violating behavioral strategy does not break _S_ with\nperfect reliability, but only with some probability, _P_ can still create an\n_expectation_ of positive profit from its attack by hedging its bets\nappropriately on _S'_. _P_ does not need a perfect attack, but merely needs to\npossess the _correct_ knowledge that _S_'s failure probability is much higher\nthan the other participants in _S_ believe it to be – because only _P_ knows\nthat (and precisely when) it will violate _S_'s design assumptions to create\nthat higher failure probability. Furthermore, even if _P_'s attack fails, and\nthe vulnerability it exploits is quickly detected and patched, _P_ may still\nprofit marginally from the market's adjustment to a realization that _S_'s\nfailure probability was (even temporarily) higher than most of _S_'s\nparticipants thought it was.\n\nWithin the context of system _S_, _P_'s behavior manifests as Byzantine\nbehavior, specifically violating the assumptions _S_'s designers thought\nparticipants would not exhibit and thus excluded from _S_'s threat model.\nConsidered in the larger context of the external world in which _S_ is embedded,\nhowever, including the external trading system _S'_, _P_'s behavior is perfectly\nrational and economically-motivated. Thus, the very rationality of _P_ in the\nlarger open world is precisely what motivates _P_ to break, and profit from,\n_S_'s ill-considered assumption that its participants would behave rationally.\n\n## Implications for Practical Systems\n\nThis type of financial attack is by no means entirely theoretical or limited to\nfully-digital systems such as cryptocurrencies. In our scenario, _P_ is\nessentially playing a game closely-analogous to the investors in\n[credit default swaps](https://en.wikipedia.org/wiki/Credit_default_swap) who\nboth contributed to, and profited handsomely from, the\n[2007-2008 financial crisis](https://en.wikipedia.org/wiki/Financial_crisis_of_2007%E2%80%932008),\nas covered more recently in the film\n[The Big Short](<https://en.wikipedia.org/wiki/The_Big_Short_(film)>).\n\nIn the cryptocurrency space, some real-world attacks we are seeing – such as\nincreasingly-common\n[51% attacks](https://cryptoslate.com/prolific-51-attacks-crypto-verge-ethereum-classic-bitcoin-gold-feathercoin-vertcoin/)\n– might be viewed as special cases of this metacircular attack on rationality.\nIt is often claimed that large proof-of-work miners (or proof-of-stake holders)\nwill not attempt 51% attacks because doing so would undermine the value of the\ncryptocurrency in which they by definition hold a large stake, and hence would\nbe “irrational”. But this argument falls apart if the attack allows the large\nstakeholder to reap rewards outside the attacked system, e.g., by defrauding\nexchanges or selling _S_ short in other systems.\n\nExternally-motivated attacks on cryptocurrencies have been predicted before in\nthe form of\n[virtual protest or \"Occupy Bitcoin\" attacks](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2041492),\n[Goldfinger attacks](https://www.econinfosec.org/archive/weis2013/papers/KrollDaveyFeltenWEIS2013.pdf),\n[puzzle transaction attacks](https://www.comp.nus.edu.sg/~prateeks/papers/38Attack.pdf),\n[merged mining attacks](https://www.sba-research.org/wp-content/uploads/publications/201709%20-%20AJudmayer%20-%20CBT_Merged_Mining_camera_ready_final.pdf),\n[hostile blockchain takeovers](https://fc18.ifca.ai/bitcoin/papers/bitcoin18-final17.pdf),\nand out-of-band variants of\n[pay-to-win attacks](https://eprint.iacr.org/2019/775.pdf). All these attacks\nare specific instances of our argument. They have been presented in the\nliterature as open yet solvable challenges. We are not aware, however, of any\nprior attempt to summarize the lessons learned and formulate a general\nimpossibility statement.\n\nFor most practical systems, we do not even know if they are incentive compatible\nin the absence of an external system _S'_ – i.e., where assumption 2 is violated\n– and probably they are not. Almost all game-theoretic treatments of (parts of)\nthe Bitcoin protocol deliver negative results. Many attacks against specific\ncryptocurrency system designs are known to be profitable in expectation, such as\n[ransaction withholding](https://www.avivz.net/pubs/12/Bitcoin_EC0212.pdf),\n[empty block mining](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2407834),\n[selfish mining](https://www.cs.cornell.edu/~ie53/publications/btcProcFC.pdf),\n[block withholding](http://webee.technion.ac.il/people/ittay/publications/btcPoolsSP15.pdf),\n[stubborn mining](https://www.cs.umd.edu/~kartik/papers/5_stubborn_eclipse.pdf),\n[fork after withholding](https://syssec.kaist.ac.kr/pub/2017/kwon_ccs_2017.pdf),\nand [whale attacks](http://www.cs.umd.edu/~jkatz/papers/whale-txs.pdf). It is\nlikely thanks only to frictions such as risk aversion and other costs that we\nrarely observe such attacks in large deployed systems. Many specific attacks do\nnot even depend on assumption 1, underlining the fact that rationality is not a\nsilver bullet even where this metacircular argument does not apply. Where it\ndoes apply, it is more general and effectively _guarantees_ the existence of\nattacks against _all_ open systems that assume participants are rational.\n\nAnother related observation is that financial markets on derivatives of a system\n_S_ mature in the external world (e.g., _S'_) as _S_ grows and becomes more\nrelevant. So in some sense, systems built on the rationality assumption are\ntemporarily more secure only until they become fat enough targets to be eaten by\ntheir own success. We can see this effect, for example, in the growing and\nincreasingly liquid market for hash power, which effectively thwarts\n[Nakamoto’s](https://bitcoin.org/bitcoin.pdf)\n([or Dwork’s](https://link.springer.com/chapter/10.1007/3-540-48071-4_10)) rule\nof thumb that the ratio of processors to individuals varies in a small band.\nSuch dynamics happen in the real world, too. But there they have traditionally\ntaken centuries or decades while in cryptocurrency space everything happens in\ntime-lapse.\n\n## Limitations of the Argument\n\nThis argument is of course currently only a rough and informal sketch. An\nenterprising student might wish to try formalizing it, or maybe someone has\nalready done so but we are unaware of it.\n\nThe metacircular argument certainly does not apply to all cryptocurrencies or\ndecentralized systems. In a permissioned system, for example, in which a closed\ngroup of participants are strongly-identified and subject to legal and\ncontractual agreements with each other, one can hope that the threat of lawsuits\nfor arbitrarily-large damages will keep rational participants incentivized to\nbehave correctly. Similarly, in a national cryptocurrency, which might be\nrelatively open but only to citizens of a given country, and which require\nverified identities with which the police can expect to track down and jail\nmisbehaving participants, this metacircular argument does not necessarily apply.\n\nApart from police enforcement, rationality assumptions may be weakened in other\nways to circumvent the metacircular argument. For example, an open system might\nbe designed according to a “weak rationality” assumption that users need\nincentives to join the system in the first place (e.g., mining rewards in\nBitcoin), but that after having become stakeholders, most will then behave\nhonestly. In this case, rational incentives serve only as a tool for system\ngrowth, but become irrelevant and equivalent to a strong honesty assumption in\nterms of the internal security of the system itself.\n\n## Conclusion: Irrationality Can Be Rational\n\n![Types of adversaries](https://bford.info/2019/09/23/rational/adversaries-open.svg)\n\nWhat many in the cryptocurrency community seem to want is a system that is both\npermissionless and tolerant of strongly-rational behavior – either beyond the\nthresholds a similar a Byzantine system would tolerate (such as a rational\nmajority), or by deriving some simplicity or efficiency benefit from assuming\nrationality. But in an open world in which the permissionless system is not the\nonly game in town, a potential _perfectly rational_ attacker can always exist,\nor appear at any time, whose entirely rational behavior is precisely to profit\nfrom bringing the system down by violating its assumptions on participant\nbehavior.\n\nSo if you think you have designed a permissionless decentralized system that is\ncleverly secured based on rationality assumptions, you haven't. You have merely\nobfuscated the rational attacker's motive and opportunity to profit outside your\nsystem from breaking your rationality assumptions. The only practical way to\neliminate this threat appears to be either to close the system and require\nstrong identities and police protection, or else secure the system against\narbitrary Byzantine behavior, thereby rendering rationality assumptions\nredundant and useless for security.\n\n> _We wish to thank Jeff Allen, Ittay Eyal, Damir Filipovic, Patrik Keller,\n> Alexander Lipton, Andrew Miller, and Haoqian Zhang for helpful feedback on\n> early drafts of this post._\n>\n> _Updated 27-Oct-2019 with link to\n> [PDF preprint](https://arxiv.org/pdf/1910.08820.pdf) version._",
    "code": "var Component=(()=>{var d=Object.create;var r=Object.defineProperty;var m=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,y=Object.prototype.hasOwnProperty;var f=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),b=(t,e)=>{for(var i in e)r(t,i,{get:e[i],enumerable:!0})},o=(t,e,i,s)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let a of p(e))!y.call(t,a)&&a!==i&&r(t,a,{get:()=>e[a],enumerable:!(s=m(e,a))||s.enumerable});return t};var g=(t,e,i)=>(i=t!=null?d(u(t)):{},o(e||!t||!t.__esModule?r(i,\"default\",{value:t,enumerable:!0}):i,t)),w=t=>o(r({},\"__esModule\",{value:!0}),t);var c=f((z,l)=>{l.exports=_jsx_runtime});var B={};b(B,{default:()=>S,frontmatter:()=>v});var n=g(c()),v={title:\"Rationality is Self-Defeating in Permissionless Systems\",description:\"How to deploy your Next.js apps on Vercel.\",image:\"/images/blog/que-eth.png\",date:\"2023-01-02\",authors:[\"Bryan Ford\"]};function h(t){let e=Object.assign({blockquote:\"blockquote\",p:\"p\",em:\"em\",a:\"a\",h2:\"h2\",span:\"span\",img:\"img\"},t.components),{Callout:i}=e;return i||x(\"Callout\",!0,\"10:1-20:11\"),(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(i,{children:(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsxs)(e.p,{children:[`Many blockchain and cryptocurrency fans seem to prefer building and analyzing\ndecentralized systems in a rational or \\u201Cgreedy behavior\\u201D failure model, rather\nthan a Byzantine or \\u201Carbitrary behavior\\u201D failure model. Many of the same\nblockchain and cryptocurrency fans also like open, permissionless systems like\nBitcoin and Ethereum, which anyone can join and participate in using weak\nidentities such as anonymous cryptography key pairs.\n`,(0,n.jsxs)(e.em,{children:[\"by \",(0,n.jsx)(e.a,{href:\"https://bford.info/\",children:\"Bryan Ford\"}),` and\n`,(0,n.jsx)(e.a,{href:\"https://informationsecurity.uibk.ac.at/people/rainer-boehme/\",children:\"Rainer Bo\\u0308hme\"}),` \\u2014\n`,(0,n.jsx)(e.a,{href:\"https://arxiv.org/pdf/1910.08820.pdf\",children:\"PDF preprint\"}),\" version available\"]})]}),`\n`]})}),`\n`,(0,n.jsx)(e.p,{children:`Many blockchain and cryptocurrency fans seem to prefer building and analyzing\ndecentralized systems in a rational or \\u201Cgreedy behavior\\u201D failure model, rather\nthan a Byzantine or \\u201Carbitrary behavior\\u201D failure model. Many of the same\nblockchain and cryptocurrency fans also like open, permissionless systems like\nBitcoin and Ethereum, which anyone can join and participate in using weak\nidentities such as anonymous cryptography key pairs.`}),`\n`,(0,n.jsxs)(e.p,{children:[`What most of these heavily-overlapping sets of fans do not seem to realize,\nhowever, is that rationality assumptions are self-defeating in open\npermissionless systems with weak identities. A fairly simple metacircular\nargument \\u2013 a kind of\n\\u201C`,(0,n.jsx)(e.a,{href:\"https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems\",children:\"G\\xF6del's incompleteness theorem\"}),`\nfor rationality\\u201D \\u2013 shows that for any system `,(0,n.jsx)(e.em,{children:\"S\"}),\" that makes \",(0,n.jsx)(e.em,{children:\"any\"}),` behavioral\nassumption, including but not limited to a rationality assumption, a rational\nattacker both exists and `,(0,n.jsx)(e.em,{children:\"has an incentive\"}),` to defeat that behavioral\nassumption, thereby violating that assumption and exhibiting Byzantine behavior\nfrom the perspective of the system.`]}),`\n`,(0,n.jsxs)(e.p,{children:[`As a quick summary of the argument we will expand below, suppose a\npermissionless system like Bitcoin is secure against rational attacks, but has\nsome weakness against irrational Byzantine attacks in which the attacker would\nlose money. Because the system is open, permissionless, and exists within a\nlarger ecosystem, a rational attacker can find ways to \\u201Cbet against\\u201D Bitcoin's\nsecurity in `,(0,n.jsx)(e.em,{children:\"other\"}),` financially-connected systems (e.g., Ethereum), making a\nprofit `,(0,n.jsx)(e.em,{children:\"outside of\"}),` Bitcoin on this attack against Bitcoin. An attack that\nappears irrational in the context of Bitcoin may be perfectly rational in the\ncontext of the larger ecosystem.`]}),`\n`,(0,n.jsxs)(e.p,{children:[`For this reason, an open permissionless system designed to be secure only\nagainst rational adversaries is actually just `,(0,n.jsx)(e.em,{children:\"insecure\"}),`, unless it remains\nsecure even when the \\u201Crational\\u201D participants become fully Byzantine. Given this,\none might as well have designed the permissionless system in a Byzantine model\nin the first place. The rationality assumption offers no actual benefit, but\nmerely can make an insecure system appear secure under flawed analysis.`]}),`\n`,(0,n.jsxs)(e.p,{children:[`This blog post is based partly on ideas in\n`,(0,n.jsx)(e.a,{href:\"https://web.archive.org/web/20191124192837/https://bdlt.school/files/slides/talk-rainer-b%C3%B6hme-a-primer-on-economics-for-cryptocurrencies.pdf\",children:\"Rainer Bo\\u0308hme's talk\"}),`\nat the recent\n`,(0,n.jsx)(e.a,{href:\"https://web.archive.org/web/20210416231544/https://bdlt.school/\",children:\"BDLT Summer School in Vienna\"}),`.\nWhile formalizing the argument would require some effort, we thought it would be\nworth at least sketching the argument intuitively for the public record.`]}),`\n`,(0,n.jsxs)(e.h2,{id:\"threat-modeling-honest-byzantine-and-rational-participants\",children:[(0,n.jsx)(e.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#threat-modeling-honest-byzantine-and-rational-participants\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Threat Modeling: Honest, Byzantine, and Rational Participants\"]}),`\n`,(0,n.jsxs)(e.p,{children:[`In designing or analyzing the security of any decentralized system, we must\ndefine the system's `,(0,n.jsx)(e.em,{children:\"threat model\"}),`, and in particular our assumptions about the\nbehaviors of the participants in the system. An `,(0,n.jsx)(e.em,{children:\"honest\"}),\", \",(0,n.jsx)(e.em,{children:\"correct\"}),`, or\n`,(0,n.jsx)(e.em,{children:\"altruistic\"}),` participant is one that we assume to follow the system's protocol\nrules as specified, hence representing a \\u201Cwell-behaved\\u201D participant exhibiting\nno adversarial behavior.`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"A \",(0,n.jsx)(e.em,{children:\"Byzantine\"}),` participant, named after the\n`,(0,n.jsx)(e.a,{href:\"http://theory.stanford.edu/~trevisan/cs174/byzantine.pdf\",children:\"Byzantine Generals Problem\"}),`,\nis one we make `,(0,n.jsx)(e.em,{children:\"no\"}),` assumptions about. A Byzantine participant can behave in\n`,(0,n.jsx)(e.em,{children:\"arbitrary\"}),` fashion, without restriction, and hence by definition represents the\nstrongest possible adversary.`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"We would like to build systems that could withstand \",(0,n.jsx)(e.em,{children:\"all\"}),` participants being\nByzantine, but this appears fundamentally impossible. We therefore in practice\nhave to make threshold security assumptions, such as that over two-thirds of the\nparticipants in classic Byzantine consensus protocols are honest, or that the\nparticipants controlling over half the hashpower in Bitcoin are well-behaved.`]}),`\n`,(0,n.jsx)(e.p,{children:`Even with threshold assumptions, however, building systems that resist Byzantine\nbehavior is extremely difficult, and the resulting systems are often much more\ncomplex and inefficient than systems tolerating weaker adversaries. We may\ntherefore be tempted to improve a design's simplicity or efficiency by making\nstronger assumptions about the behavior of adversarial participants, effectively\nweakening the assumed adversary.`}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"https://bford.info/2019/09/23/rational/adversaries.svg\",alt:\"Types of adversaries\"})}),`\n`,(0,n.jsxs)(e.p,{children:[\"One such popular assumption, especially in economic circles, is \",(0,n.jsx)(e.em,{children:\"rationality\"}),`.\nIn essence, we assume that rational participants may deviate from the rules in\narbitrary ways but `,(0,n.jsx)(e.em,{children:\"only when doing so is in their economic self-interest\"}),`,\nimproving their expected rewards \\u2013 usually but not always financial \\u2013 in\ncomparison with following the rules honestly.`]}),`\n`,(0,n.jsxs)(e.p,{children:[`By assuming that adversarial participants are rational rather than Byzantine, we\nneed not secure the system against `,(0,n.jsx)(e.em,{children:\"all\"}),` possible participant behaviors, such as\nagainst participants who pay money with no reward merely to sow chaos and\ndestruction. Instead, we merely need to prove that the system is `,(0,n.jsx)(e.em,{children:`incentive\ncompatible`}),`, for example by showing that its rules represent a Nash equilibrium,\nin which deviations from the equilibrium will not give participants a greater\nfinancial reward.`]}),`\n`,(0,n.jsxs)(e.p,{children:[`Besides simplicity and efficiency, another appeal of rationality assumptions is\nthe promise of `,(0,n.jsx)(e.em,{children:\"strengthening\"}),` the system's security by lowering the threshold\nof participants we assume to be fully honest. To circumvent the classical\nByzantine consensus requirement that fewer than one third of participants may be\nfaulty, for example, we might hope to tolerate closer to 50%, or even 100%, of\nparticipants being \\u201Cadversarial\\u201D if we assume they are rational and not\nByzantine. Work on\n`,(0,n.jsx)(e.a,{href:\"http://www.cs.utexas.edu/~lorenzo/papers/sosp05.pdf\",children:\"the BAR model (Byzantine-Altruistic-Rational)\"}),`\nand\n`,(0,n.jsxs)(e.a,{href:\"http://www.cs.utexas.edu/~lorenzo/papers/Abraham11Distributed.pdf\",children:[(0,n.jsx)(e.em,{children:\"(k,t)\"}),\"-robustness\"]}),`\nexemplifies this goal, which sometimes appears achievable in closed systems with\nstrong identities. But a direct implication of our metacircular argument is that\nan `,(0,n.jsx)(e.em,{children:\"open\"}),` system cannot generally be secure if all participants are either\nByzantine or rational.`]}),`\n`,(0,n.jsxs)(e.h2,{id:\"assumptions-underlying-the-argument\",children:[(0,n.jsx)(e.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#assumptions-underlying-the-argument\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Assumptions Underlying the Argument\"]}),`\n`,(0,n.jsx)(e.p,{children:\"The metacircular argument makes three main assumptions.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"First, the system \",(0,n.jsx)(e.em,{children:\"S\"}),` under consideration is open and permissionless, allowing\nanyone to join and participate in the system using only weak, anonymous\nidentities such as bare cryptographic key pairs. Identities in `,(0,n.jsx)(e.em,{children:\"S\"}),` need not even\nbe costless provided their price is modest: the argument still works even if `,(0,n.jsx)(e.em,{children:\"S\"}),`\nimposes membership fees or requires new wallet keys to be \\u201Cmined\\u201D, for example.\nProof-of-Work cryptocurrencies such as Bitcoin and Ethereum, Proof-of-Stake\nsystems such as Algorand and Ouroboros, and most other permissionless systems\nseem to satisfy this openness property. Because participation is open to anyone\nglobally and can be anonymous, we cannot reasonably expect police or governments\nto protect `,(0,n.jsx)(e.em,{children:\"S\"}),` from attack: even if they wanted to and considered it their job,\nthey would not be able to find or discipline a smart rational attacker who might\nbe attacking from anywhere around the globe, especially from a country with weak\ninternational agreements and extradition rules. Thus, `,(0,n.jsx)(e.em,{children:\"S\"}),` must \\u201Cstand on its\nown\\u201D, by successfully either withstanding or disincentivizing attacks coming\nfrom anywhere. (And it will turn out that merely disincentivizing such attacks\nis impossible.)`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Second, the system \",(0,n.jsx)(e.em,{children:\"S\"}),` does not control a majority of total economic power or\nvalue in the world: i.e., it is not totally economically dominant from a global\nperspective. Instead, there may be (and probably are) actors outside of `,(0,n.jsx)(e.em,{children:\"S\"}),` who,\nif rationally incentivized to do so, can at least temporarily muster an amount\nof economic power outside of `,(0,n.jsx)(e.em,{children:\"S\"}),` comparable to or greater than the economic\nvalue within or controlled by `,(0,n.jsx)(e.em,{children:\"S\"}),\". In other words, we assume that \",(0,n.jsx)(e.em,{children:\"S\"}),` is not the\n\\u201Cbiggest fish in the ocean.\\u201D Given that there can be at most one globally\ndominant economic system at a time, it seems neither useful nor advisable to\ndesign systems that are secure only when they are the biggest fish in the ocean,\nbecause almost always they are not.`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Third, the system \",(0,n.jsx)(e.em,{children:\"S\"}),\" actually \",(0,n.jsx)(e.em,{children:\"leverages\"}),` in some fashion the behavioral\nassumption(s) it makes on participants, such as a rationality assumption. That\nis, we assume there exist one or more (arbitrary) behavioral strategies that `,(0,n.jsx)(e.em,{children:\"S\"}),`\nassumes some participants `,(0,n.jsx)(e.em,{children:\"will not\"}),` follow, such as economically-losing\nbehaviors in the case of rationality. Further, we assume there exists such an\nassumption-violating strategy that will cause `,(0,n.jsx)(e.em,{children:\"S\"}),` to malfunction or otherwise\ndeviate observably from its correct operation. In fact, we need not assume that\nthis deviant behavior will `,(0,n.jsx)(e.em,{children:\"always\"}),\" succeed in breaking \",(0,n.jsx)(e.em,{children:\"S\"}),`, but only that it\nwill non-negligibly `,(0,n.jsx)(e.em,{children:\"raise the probability\"}),\" of \",(0,n.jsx)(e.em,{children:\"S\"}),` failing. If this were not the\ncase, and `,(0,n.jsx)(e.em,{children:\"S\"}),` in fact operates correctly, securely, and indistinguishably from\nits ideal even if participants do violate their behavioral assumptions, then `,(0,n.jsx)(e.em,{children:\"S\"}),`\nis actually Byzantine secure after all. In that case, `,(0,n.jsx)(e.em,{children:\"S\"}),` is not actually\nbenefiting from its assumptions about participant behavior, which are redundant\nand thus may be simply discarded.`]}),`\n`,(0,n.jsxs)(e.h2,{id:\"the-metacircular-argument-rational-attacks-on-rationality\",children:[(0,n.jsx)(e.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#the-metacircular-argument-rational-attacks-on-rationality\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"The Metacircular Argument: Rational Attacks on Rationality\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Suppose permissionless system \",(0,n.jsx)(e.em,{children:\"S\"}),` is launched, and operates smoothly for some\ntime, with all participants conforming to `,(0,n.jsx)(e.em,{children:\"S\"}),`'s assumptions about them. Because\n`,(0,n.jsx)(e.em,{children:\"S\"}),` is permissionless (assumption 1) and exists in a larger open world\n(assumption 2), new rational participants may arrive at any time, attracted by\n`,(0,n.jsx)(e.em,{children:\"S\"}),`'s success and presumably growing economic value provided there is an\nopportunity to profit from doing so.`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Consider a particular newly-arriving participant \",(0,n.jsx)(e.em,{children:\"P\"}),\". \",(0,n.jsx)(e.em,{children:\"P\"}),` could of course play\nby the rules `,(0,n.jsx)(e.em,{children:\"S\"}),\" assumes of \",(0,n.jsx)(e.em,{children:\"P\"}),`, in which case the greatest immediate economic\nbenefit `,(0,n.jsx)(e.em,{children:\"P\"}),\" could derive from participating in \",(0,n.jsx)(e.em,{children:\"S\"}),` is some fraction of the total\neconomic value currently embodied in `,(0,n.jsx)(e.em,{children:\"S\"}),` (e.g., its market cap). For most\nrealistic permissionless systems embodying strong founders' or early-adopters'\nrewards, if `,(0,n.jsx)(e.em,{children:\"P\"}),\" is not one of the original founders of \",(0,n.jsx)(e.em,{children:\"S\"}),` but arrives\nsubstantially after launch, then `,(0,n.jsx)(e.em,{children:\"P\"}),`'s near-term payoff prospectives from\njoining `,(0,n.jsx)(e.em,{children:\"S\"}),\" is likely bounded to a fairly \",(0,n.jsx)(e.em,{children:\"small\"}),\" fraction of \",(0,n.jsx)(e.em,{children:\"S\"}),`'s total value.\nBut what if there were another strategy `,(0,n.jsx)(e.em,{children:\"P\"}),\" could take, for perfectly \",(0,n.jsx)(e.em,{children:\"rational\"}),`\nand economically-motivated reasons, by which `,(0,n.jsx)(e.em,{children:\"P\"}),` could in relatively short order\nacquire a `,(0,n.jsx)(e.em,{children:\"large\"}),\" fraction of \",(0,n.jsx)(e.em,{children:\"S\"}),\"'s total value?\"]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"https://bford.info/2019/09/23/rational/open-world.svg\",alt:\"Open world with S and S'\"})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Because \",(0,n.jsx)(e.em,{children:\"S\"}),\" is permissionless and operating in a larger open world, \",(0,n.jsx)(e.em,{children:\"P\"}),` is not\nconfined to operating exclusively within the boundaries of `,(0,n.jsx)(e.em,{children:\"S\"}),\". \",(0,n.jsx)(e.em,{children:\"P\"}),` can also\nmake use of facilities external to `,(0,n.jsx)(e.em,{children:\"S\"}),\". By assumption 2, \",(0,n.jsx)(e.em,{children:\"P\"}),` may in particular\nhave access to, or be able to borrow temporarily, financial resources comparable\nto or larger than the total value of `,(0,n.jsx)(e.em,{children:\"S\"}),\".\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Suppose the facilities external to \",(0,n.jsx)(e.em,{children:\"S\"}),` include another Ethereum-like\ncryptocurrency `,(0,n.jsx)(e.em,{children:\"S'\"}),`, which includes a smart contract facility with which\ndecentralized exchanges, futures markets, and the like may be implemented. (This\nis not really a separate assumption because even if `,(0,n.jsx)(e.em,{children:\"S'\"}),` did not already exist,\n`,(0,n.jsx)(e.em,{children:\"P\"}),` could create and launch it, given sufficient economic resources under\nassumption 2.) Further, suppose that someone (perhaps `,(0,n.jsx)(e.em,{children:\"P\"}),`) has created on\nexternal system `,(0,n.jsx)(e.em,{children:\"S'\"}),` a decentralized exchange, futures market, or any other\nmechanism by which tokens representing shares of the value of `,(0,n.jsx)(e.em,{children:\"S\"}),` may be traded\nor speculated upon in the context of `,(0,n.jsx)(e.em,{children:\"S'\"}),`: e.g., a series of tradeable Ethereum\ntokens pegged to `,(0,n.jsx)(e.em,{children:\"S\"}),\"'s cryptocurrency or stake units.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Now suppose participant \",(0,n.jsx)(e.em,{children:\"P\"}),\" finds some behavioral strategy that system \",(0,n.jsx)(e.em,{children:\"S\"}),`\ndepends on participants `,(0,n.jsx)(e.em,{children:\"not\"}),\" exhibiting, and that will observably break \",(0,n.jsx)(e.em,{children:\"S\"}),` \\u2013\nor even that just `,(0,n.jsx)(e.em,{children:\"might\"}),\" break \",(0,n.jsx)(e.em,{children:\"S\"}),` with significant non-negligible probability.\nAssumption 3 above guarantees the existence of such a behavioral strategy,\nunless `,(0,n.jsx)(e.em,{children:\"S\"}),\"'s rationality assumptions were in fact redundant and worthless. \",(0,n.jsx)(e.em,{children:\"P\"}),`\nmust merely be clever enough to find and implement such a strategy. It is\npossible this strategy might first require `,(0,n.jsx)(e.em,{children:\"P\"}),` to pretend to be one or more\nwell-behaved participants of `,(0,n.jsx)(e.em,{children:\"S\"}),` for a while, to build up the necessary\nreputation or otherwise get correctly positioned in `,(0,n.jsx)(e.em,{children:\"S\"}),`'s state space; a bit of\npatience and persistence on `,(0,n.jsx)(e.em,{children:\"P\"}),\"'s part will satisfy this requirement. \",(0,n.jsx)(e.em,{children:\"P\"}),` may\nalso have to \\u201Cbuy into\\u201D `,(0,n.jsx)(e.em,{children:\"S\"}),` enough to surmount any entry costs or stake\nthresholds `,(0,n.jsx)(e.em,{children:\"S\"}),\" might impose; the external funds \",(0,n.jsx)(e.em,{children:\"P\"}),` can invoke or borrow by\nassumption 2 can satisfy this requirement, and are bounded by the total value of\n`,(0,n.jsx)(e.em,{children:\"S\"}),\". In general, \",(0,n.jsx)(e.em,{children:\"S\"}),`'s openness by assumption 1 and the existence of a\ncorrectness-violating strategy by assumption 3 ensures that there exists some\ncourse of action and supply of external resources by which `,(0,n.jsx)(e.em,{children:\"P\"}),` can position\nitself to violate `,(0,n.jsx)(e.em,{children:\"S\"}),\"'s behavioral assumption.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"In addition to infiltrating and positioning itself within \",(0,n.jsx)(e.em,{children:\"S\"}),\", \",(0,n.jsx)(e.em,{children:\"P\"}),` also invokes\nor borrows enough external funds and uses them to short-sell (bet against)\nshares of `,(0,n.jsx)(e.em,{children:\"S\"}),\"'s value massively in the context of the external system \",(0,n.jsx)(e.em,{children:\"S'\"}),`,\nwhich (unlike `,(0,n.jsx)(e.em,{children:\"S\"}),\") \",(0,n.jsx)(e.em,{children:\"P\"}),` trusts will remain operational and hold its value\nindependently of `,(0,n.jsx)(e.em,{children:\"S\"}),\". Provided \",(0,n.jsx)(e.em,{children:\"P\"}),` reaches this short-selling position gradually\nand carefully enough to avoid revealing its strategy early, the funds `,(0,n.jsx)(e.em,{children:\"P\"}),` must\ninvoke or borrow for this purpose must be bounded by some fraction of the total\neconomic value of `,(0,n.jsx)(e.em,{children:\"S\"}),`. And provided there are at least some participants and/or\nobservers of `,(0,n.jsx)(e.em,{children:\"S\"}),\" who believe that \",(0,n.jsx)(e.em,{children:\"S\"}),` is secure and will remain operating\ncorrectly, and are willing to bet to that effect on `,(0,n.jsx)(e.em,{children:\"S'\"}),\", \",(0,n.jsx)(e.em,{children:\"P\"}),` will eventually be\nable to build its short position.`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Finally, once \",(0,n.jsx)(e.em,{children:\"P\"}),\" is positioned correctly within both \",(0,n.jsx)(e.em,{children:\"S\"}),\" and \",(0,n.jsx)(e.em,{children:\"S'\"}),\", \",(0,n.jsx)(e.em,{children:\"P\"}),` then\nlaunches its assumption-violating behavior in `,(0,n.jsx)(e.em,{children:\"S\"}),\" that will observably cause \",(0,n.jsx)(e.em,{children:\"S\"}),`\nto fail as per assumption 2. This might manifest as a denial-of-service attack,\na correctness attack, or in any other fashion. The only requirement is that\n`,(0,n.jsx)(e.em,{children:\"P\"}),\"'s behavior creates an \",(0,n.jsx)(e.em,{children:\"observable\"}),` failure, which a nontrivial number of the\nexisting participants in `,(0,n.jsx)(e.em,{children:\"S\"}),` believed would not happen because they believed in\n`,(0,n.jsx)(e.em,{children:\"S\"}),\" and its threat model. The fact that \",(0,n.jsx)(e.em,{children:\"S\"}),` is now observed to be broken, and\nits basic design assumptions manifestly violated, causes the shares of `,(0,n.jsx)(e.em,{children:\"S\"}),`'s\nvalue to drop precipitously on external market `,(0,n.jsx)(e.em,{children:\"S'\"}),\", on which \",(0,n.jsx)(e.em,{children:\"P\"}),` takes a\nhandsome profit. Perhaps `,(0,n.jsx)(e.em,{children:\"S\"}),` recovers and continues, or perhaps it fails\nentirely \\u2013 but either way, `,(0,n.jsx)(e.em,{children:\"P\"}),` has essentially transferred a significant\nfraction of system `,(0,n.jsx)(e.em,{children:\"S\"}),\"'s economic value from system \",(0,n.jsx)(e.em,{children:\"S\"}),\" itself to \",(0,n.jsx)(e.em,{children:\"P\"}),`'s own\nshort-sold position on external market `,(0,n.jsx)(e.em,{children:\"S'\"}),\". And to do so, \",(0,n.jsx)(e.em,{children:\"P\"}),` needed only to\nfind a way \\u2013 any way \\u2013 to `,(0,n.jsx)(e.em,{children:\"surprise\"}),\" all those who believed \",(0,n.jsx)(e.em,{children:\"S\"}),` was secure and\nthat its threat model accurately modeled `,(0,n.jsx)(e.em,{children:\"S\"}),\"'s real-world participants.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Even if \",(0,n.jsx)(e.em,{children:\"P\"}),\"'s assumption-violating behavioral strategy does not break \",(0,n.jsx)(e.em,{children:\"S\"}),` with\nperfect reliability, but only with some probability, `,(0,n.jsx)(e.em,{children:\"P\"}),` can still create an\n`,(0,n.jsx)(e.em,{children:\"expectation\"}),` of positive profit from its attack by hedging its bets\nappropriately on `,(0,n.jsx)(e.em,{children:\"S'\"}),\". \",(0,n.jsx)(e.em,{children:\"P\"}),` does not need a perfect attack, but merely needs to\npossess the `,(0,n.jsx)(e.em,{children:\"correct\"}),\" knowledge that \",(0,n.jsx)(e.em,{children:\"S\"}),`'s failure probability is much higher\nthan the other participants in `,(0,n.jsx)(e.em,{children:\"S\"}),\" believe it to be \\u2013 because only \",(0,n.jsx)(e.em,{children:\"P\"}),` knows\nthat (and precisely when) it will violate `,(0,n.jsx)(e.em,{children:\"S\"}),`'s design assumptions to create\nthat higher failure probability. Furthermore, even if `,(0,n.jsx)(e.em,{children:\"P\"}),`'s attack fails, and\nthe vulnerability it exploits is quickly detected and patched, `,(0,n.jsx)(e.em,{children:\"P\"}),` may still\nprofit marginally from the market's adjustment to a realization that `,(0,n.jsx)(e.em,{children:\"S\"}),`'s\nfailure probability was (even temporarily) higher than most of `,(0,n.jsx)(e.em,{children:\"S\"}),`'s\nparticipants thought it was.`]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Within the context of system \",(0,n.jsx)(e.em,{children:\"S\"}),\", \",(0,n.jsx)(e.em,{children:\"P\"}),`'s behavior manifests as Byzantine\nbehavior, specifically violating the assumptions `,(0,n.jsx)(e.em,{children:\"S\"}),`'s designers thought\nparticipants would not exhibit and thus excluded from `,(0,n.jsx)(e.em,{children:\"S\"}),`'s threat model.\nConsidered in the larger context of the external world in which `,(0,n.jsx)(e.em,{children:\"S\"}),` is embedded,\nhowever, including the external trading system `,(0,n.jsx)(e.em,{children:\"S'\"}),\", \",(0,n.jsx)(e.em,{children:\"P\"}),`'s behavior is perfectly\nrational and economically-motivated. Thus, the very rationality of `,(0,n.jsx)(e.em,{children:\"P\"}),` in the\nlarger open world is precisely what motivates `,(0,n.jsx)(e.em,{children:\"P\"}),` to break, and profit from,\n`,(0,n.jsx)(e.em,{children:\"S\"}),\"'s ill-considered assumption that its participants would behave rationally.\"]}),`\n`,(0,n.jsxs)(e.h2,{id:\"implications-for-practical-systems\",children:[(0,n.jsx)(e.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#implications-for-practical-systems\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Implications for Practical Systems\"]}),`\n`,(0,n.jsxs)(e.p,{children:[`This type of financial attack is by no means entirely theoretical or limited to\nfully-digital systems such as cryptocurrencies. In our scenario, `,(0,n.jsx)(e.em,{children:\"P\"}),` is\nessentially playing a game closely-analogous to the investors in\n`,(0,n.jsx)(e.a,{href:\"https://en.wikipedia.org/wiki/Credit_default_swap\",children:\"credit default swaps\"}),` who\nboth contributed to, and profited handsomely from, the\n`,(0,n.jsx)(e.a,{href:\"https://en.wikipedia.org/wiki/Financial_crisis_of_2007%E2%80%932008\",children:\"2007-2008 financial crisis\"}),`,\nas covered more recently in the film\n`,(0,n.jsx)(e.a,{href:\"https://en.wikipedia.org/wiki/The_Big_Short_(film)\",children:\"The Big Short\"}),\".\"]}),`\n`,(0,n.jsxs)(e.p,{children:[`In the cryptocurrency space, some real-world attacks we are seeing \\u2013 such as\nincreasingly-common\n`,(0,n.jsx)(e.a,{href:\"https://cryptoslate.com/prolific-51-attacks-crypto-verge-ethereum-classic-bitcoin-gold-feathercoin-vertcoin/\",children:\"51% attacks\"}),`\n\\u2013 might be viewed as special cases of this metacircular attack on rationality.\nIt is often claimed that large proof-of-work miners (or proof-of-stake holders)\nwill not attempt 51% attacks because doing so would undermine the value of the\ncryptocurrency in which they by definition hold a large stake, and hence would\nbe \\u201Cirrational\\u201D. But this argument falls apart if the attack allows the large\nstakeholder to reap rewards outside the attacked system, e.g., by defrauding\nexchanges or selling `,(0,n.jsx)(e.em,{children:\"S\"}),\" short in other systems.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[`Externally-motivated attacks on cryptocurrencies have been predicted before in\nthe form of\n`,(0,n.jsx)(e.a,{href:\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2041492\",children:'virtual protest or \"Occupy Bitcoin\" attacks'}),`,\n`,(0,n.jsx)(e.a,{href:\"https://www.econinfosec.org/archive/weis2013/papers/KrollDaveyFeltenWEIS2013.pdf\",children:\"Goldfinger attacks\"}),`,\n`,(0,n.jsx)(e.a,{href:\"https://www.comp.nus.edu.sg/~prateeks/papers/38Attack.pdf\",children:\"puzzle transaction attacks\"}),`,\n`,(0,n.jsx)(e.a,{href:\"https://www.sba-research.org/wp-content/uploads/publications/201709%20-%20AJudmayer%20-%20CBT_Merged_Mining_camera_ready_final.pdf\",children:\"merged mining attacks\"}),`,\n`,(0,n.jsx)(e.a,{href:\"https://fc18.ifca.ai/bitcoin/papers/bitcoin18-final17.pdf\",children:\"hostile blockchain takeovers\"}),`,\nand out-of-band variants of\n`,(0,n.jsx)(e.a,{href:\"https://eprint.iacr.org/2019/775.pdf\",children:\"pay-to-win attacks\"}),`. All these attacks\nare specific instances of our argument. They have been presented in the\nliterature as open yet solvable challenges. We are not aware, however, of any\nprior attempt to summarize the lessons learned and formulate a general\nimpossibility statement.`]}),`\n`,(0,n.jsxs)(e.p,{children:[`For most practical systems, we do not even know if they are incentive compatible\nin the absence of an external system `,(0,n.jsx)(e.em,{children:\"S'\"}),` \\u2013 i.e., where assumption 2 is violated\n\\u2013 and probably they are not. Almost all game-theoretic treatments of (parts of)\nthe Bitcoin protocol deliver negative results. Many attacks against specific\ncryptocurrency system designs are known to be profitable in expectation, such as\n`,(0,n.jsx)(e.a,{href:\"https://www.avivz.net/pubs/12/Bitcoin_EC0212.pdf\",children:\"ransaction withholding\"}),`,\n`,(0,n.jsx)(e.a,{href:\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2407834\",children:\"empty block mining\"}),`,\n`,(0,n.jsx)(e.a,{href:\"https://www.cs.cornell.edu/~ie53/publications/btcProcFC.pdf\",children:\"selfish mining\"}),`,\n`,(0,n.jsx)(e.a,{href:\"http://webee.technion.ac.il/people/ittay/publications/btcPoolsSP15.pdf\",children:\"block withholding\"}),`,\n`,(0,n.jsx)(e.a,{href:\"https://www.cs.umd.edu/~kartik/papers/5_stubborn_eclipse.pdf\",children:\"stubborn mining\"}),`,\n`,(0,n.jsx)(e.a,{href:\"https://syssec.kaist.ac.kr/pub/2017/kwon_ccs_2017.pdf\",children:\"fork after withholding\"}),`,\nand `,(0,n.jsx)(e.a,{href:\"http://www.cs.umd.edu/~jkatz/papers/whale-txs.pdf\",children:\"whale attacks\"}),`. It is\nlikely thanks only to frictions such as risk aversion and other costs that we\nrarely observe such attacks in large deployed systems. Many specific attacks do\nnot even depend on assumption 1, underlining the fact that rationality is not a\nsilver bullet even where this metacircular argument does not apply. Where it\ndoes apply, it is more general and effectively `,(0,n.jsx)(e.em,{children:\"guarantees\"}),` the existence of\nattacks against `,(0,n.jsx)(e.em,{children:\"all\"}),\" open systems that assume participants are rational.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[`Another related observation is that financial markets on derivatives of a system\n`,(0,n.jsx)(e.em,{children:\"S\"}),\" mature in the external world (e.g., \",(0,n.jsx)(e.em,{children:\"S'\"}),\") as \",(0,n.jsx)(e.em,{children:\"S\"}),` grows and becomes more\nrelevant. So in some sense, systems built on the rationality assumption are\ntemporarily more secure only until they become fat enough targets to be eaten by\ntheir own success. We can see this effect, for example, in the growing and\nincreasingly liquid market for hash power, which effectively thwarts\n`,(0,n.jsx)(e.a,{href:\"https://bitcoin.org/bitcoin.pdf\",children:\"Nakamoto\\u2019s\"}),`\n(`,(0,n.jsx)(e.a,{href:\"https://link.springer.com/chapter/10.1007/3-540-48071-4_10\",children:\"or Dwork\\u2019s\"}),`) rule\nof thumb that the ratio of processors to individuals varies in a small band.\nSuch dynamics happen in the real world, too. But there they have traditionally\ntaken centuries or decades while in cryptocurrency space everything happens in\ntime-lapse.`]}),`\n`,(0,n.jsxs)(e.h2,{id:\"limitations-of-the-argument\",children:[(0,n.jsx)(e.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#limitations-of-the-argument\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Limitations of the Argument\"]}),`\n`,(0,n.jsx)(e.p,{children:`This argument is of course currently only a rough and informal sketch. An\nenterprising student might wish to try formalizing it, or maybe someone has\nalready done so but we are unaware of it.`}),`\n`,(0,n.jsx)(e.p,{children:`The metacircular argument certainly does not apply to all cryptocurrencies or\ndecentralized systems. In a permissioned system, for example, in which a closed\ngroup of participants are strongly-identified and subject to legal and\ncontractual agreements with each other, one can hope that the threat of lawsuits\nfor arbitrarily-large damages will keep rational participants incentivized to\nbehave correctly. Similarly, in a national cryptocurrency, which might be\nrelatively open but only to citizens of a given country, and which require\nverified identities with which the police can expect to track down and jail\nmisbehaving participants, this metacircular argument does not necessarily apply.`}),`\n`,(0,n.jsx)(e.p,{children:`Apart from police enforcement, rationality assumptions may be weakened in other\nways to circumvent the metacircular argument. For example, an open system might\nbe designed according to a \\u201Cweak rationality\\u201D assumption that users need\nincentives to join the system in the first place (e.g., mining rewards in\nBitcoin), but that after having become stakeholders, most will then behave\nhonestly. In this case, rational incentives serve only as a tool for system\ngrowth, but become irrelevant and equivalent to a strong honesty assumption in\nterms of the internal security of the system itself.`}),`\n`,(0,n.jsxs)(e.h2,{id:\"conclusion-irrationality-can-be-rational\",children:[(0,n.jsx)(e.a,{className:\"subheading-anchor\",\"aria-label\":\"Link to section\",href:\"#conclusion-irrationality-can-be-rational\",children:(0,n.jsx)(e.span,{className:\"icon icon-link\"})}),\"Conclusion: Irrationality Can Be Rational\"]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"https://bford.info/2019/09/23/rational/adversaries-open.svg\",alt:\"Types of adversaries\"})}),`\n`,(0,n.jsxs)(e.p,{children:[`What many in the cryptocurrency community seem to want is a system that is both\npermissionless and tolerant of strongly-rational behavior \\u2013 either beyond the\nthresholds a similar a Byzantine system would tolerate (such as a rational\nmajority), or by deriving some simplicity or efficiency benefit from assuming\nrationality. But in an open world in which the permissionless system is not the\nonly game in town, a potential `,(0,n.jsx)(e.em,{children:\"perfectly rational\"}),` attacker can always exist,\nor appear at any time, whose entirely rational behavior is precisely to profit\nfrom bringing the system down by violating its assumptions on participant\nbehavior.`]}),`\n`,(0,n.jsx)(e.p,{children:`So if you think you have designed a permissionless decentralized system that is\ncleverly secured based on rationality assumptions, you haven't. You have merely\nobfuscated the rational attacker's motive and opportunity to profit outside your\nsystem from breaking your rationality assumptions. The only practical way to\neliminate this threat appears to be either to close the system and require\nstrong identities and police protection, or else secure the system against\narbitrary Byzantine behavior, thereby rendering rationality assumptions\nredundant and useless for security.`}),`\n`,(0,n.jsxs)(e.blockquote,{children:[`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.em,{children:`We wish to thank Jeff Allen, Ittay Eyal, Damir Filipovic, Patrik Keller,\nAlexander Lipton, Andrew Miller, and Haoqian Zhang for helpful feedback on\nearly drafts of this post.`})}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsxs)(e.em,{children:[`Updated 27-Oct-2019 with link to\n`,(0,n.jsx)(e.a,{href:\"https://arxiv.org/pdf/1910.08820.pdf\",children:\"PDF preprint\"}),\" version.\"]})}),`\n`]})]})}function k(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(h,t)})):h(t)}var S=k;function x(t,e,i){throw new Error(\"Expected \"+(e?\"component\":\"object\")+\" `\"+t+\"` to be defined: you likely forgot to import, pass, or provide it.\"+(i?\"\\nIt\\u2019s referenced in your code at `\"+i+\"` in `/Users/janitor/resite/content/blog/_mdx_bundler_entry_point-cb2f6093-4066-4324-bb06-25ba23129737.mdx`\":\"\"))}return w(B);})();\n;return Component;"
  },
  "_id": "blog/rationality-is-self-defeating.mdx",
  "_raw": {
    "sourceFilePath": "blog/rationality-is-self-defeating.mdx",
    "sourceFileName": "rationality-is-self-defeating.mdx",
    "sourceFileDir": "blog",
    "contentType": "mdx",
    "flattenedPath": "blog/rationality-is-self-defeating"
  },
  "type": "Post",
  "slug": "/blog/rationality-is-self-defeating",
  "slugAsParams": "rationality-is-self-defeating"
}